# 1. Text Generation with GPT-2: Experiment with OpenAI's GPT-2 model for generating diverse and coherent text based on prompts.

import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer
def generate_text(prompt, model_name="gpt2", max_length=100, temperature=0.7, top_k=50, top_p=0.9):
  tokenizer = GPT2Tokenizer.from_pretrained(model_name)
  model = GPT2LMHeadModel.from_pretrained(model_name)

  # Encode the prompt
  input_ids = tokenizer.encode(prompt, return_tensors="pt")

  # Generate text
  with torch.no_grad():
    output = model.generate(
        input_ids,
        max_length=max_length,
        temperature=temperature,
        top_k=top_k,
        top_p=top_p,
        do_sample=True
    )

  # Decode the output
  generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
  return generated_text

if __name__ == "__main__":
   prompt_text=input("Enter your prompt: ")
   generated_text = generate_text(prompt_text)
   print("\ngenerated text:\n", generated_text)
